import sympy as sp

class PXLAnalyzer:
    """
    Protopraxic Logic (PXL) Concept Analyzer.
    
    This class provides a runtime tool for analyzing predicates or propositions using PXL's
    coherence-driven framework. It integrates classical logic variants (negation, conjunction,
    disjunction, implication) and modal variants (necessity, possibility), treating negation
    as privation without equal opposition. Evaluations prioritize positive coherence grounding
    in the triune structure (ğ•€â‚, ğ•€â‚‚, ğ•€â‚ƒ) of the Necessary Being ğ•†, with negated forms
    collapsing to privative status.
    
    Usage:
    analyzer = PXLAnalyzer()
    result = analyzer.analyze_concept("P", "Optional context for paradox detection")
    """
    
    def __init__(self):
        # Classical symbols (mapped to SymPy for evaluation)
        self.neg = lambda p: sp.Not(p)  # Â¬ as privation (non-coherence)
        self.conj = lambda p, q: sp.And(p, q)  # âˆ§
        self.disj = lambda p, q: sp.Or(p, q)  # âˆ¨
        self.impl = lambda p, q: sp.Implies(p, q)  # â†’
        
        # Modal symbols
        self.necessity = lambda p: sp.Function('â–¡')(p)  # â–¡
        self.possibility = lambda p: sp.Function('â—‡')(p)  # â—‡
        
        # PXL-specific operators (functional mappings)
        self.coheres = lambda x, y: sp.Eq(x, y)  # â§Ÿ: self-coherence
        self.exclusive = lambda x, y: sp.Not(sp.Eq(x, y))  # â‡: non-equivalence
        self.balance = lambda x, y: sp.And(sp.Eq(x, y), sp.Not(sp.Eq(x, sp.Not(y))))  # â‡Œ: interchange/balance
        self.dichotomy = lambda p: sp.Or(p, sp.Not(p))  # â«´: excluded middle (with positive priority)
        self.grounded_entail = lambda x, p: sp.Implies(x, p)  # âŸ¼: grounded entailment
        self.modal_equiv = lambda p, q: sp.And(self.necessity(sp.Eq(p, q)))  # â©ª: modal coherence equivalence
        
        # Triune symbols
        self.I1 = sp.Symbol('ğ•€â‚')  # Identity grounding
        self.I2 = sp.Symbol('ğ•€â‚‚')  # Non-contradiction (privation for negations)
        self.I3 = sp.Symbol('ğ•€â‚ƒ')  # Excluded middle (dichotomy without equal opposition)
        self.O = sp.Symbol('ğ•†')  # Necessary Being

    def analyze_concept(self, P_str: str, context: str = ""):
        """
        Analyze a predicate or proposition for coherence, classification, and paradoxes.
        
        Args:
            P_str (str): The predicate/proposition (e.g., "x â§Ÿ x" or "Truth").
            context (str, optional): Additional context for paradox detection.
        
        Returns:
            dict: Analysis results including checks and classification.
        """
        # Parse input to SymPy (handle simple strings; advanced parsing can be extended)
        try:
            P = sp.sympify(P_str, evaluate=False)
        except:
            P = sp.Symbol(P_str)  # Fallback for non-parsable strings
        
        # Classical evaluation (compose if compound)
        classical_eval = str(P)  # Can extend to full truth-table simulation if needed
        
        # Modal application
        modal_P = self.necessity(P)
        
        # Triune grounding checks (with privation for negation)
        i1_check = self._check_i1(P)
        i2_check = self._check_i2(P)
        i3_check = self._check_i3(P)
        
        # Classification with privation bias and no equal opposition
        entails_O_P = self._entails_O(P)
        if entails_O_P == "necessary":
            classification = "Fundamental (Coherence-Grounded in ğ•†)"
        elif entails_O_P == "possible":
            classification = "Derived (Contingent Coherence)"
        else:
            classification = "Privative (Incoherent or Negated Form)"
        
        # Paradox detection
        paradox_type = self._detect_paradox(context)
        
        return {
            "Classical Evaluation": classical_eval,
            "Modal Form": str(modal_P),
            "ğ•€â‚ Check (Identity Coherence)": i1_check,
            "ğ•€â‚‚ Check (Non-Contradiction, Privation)": i2_check,
            "ğ•€â‚ƒ Check (Dichotomy, Positive Priority)": i3_check,
            "Ontological Classification": classification,
            "Paradox Detected": paradox_type
        }

    def _check_i1(self, P):
        """ğ•€â‚: Determinate self-coherence via â§Ÿ."""
        self_coherence = self.coheres(P, P)
        return "Satisfies" if self_coherence == True else "Fails (Identity Privation)"

    def _check_i2(self, P):
        """ğ•€â‚‚: Non-contradiction via â‡; negation as privation."""
        neg_P = self.neg(P)
        contradiction = self.conj(P, neg_P)
        if contradiction == True:
            return "Fails (Privative Collapse to Incoherence)"
        return "Satisfies (Exclusivity Preserved)"

    def _check_i3(self, P):
        """ğ•€â‚ƒ: Dichotomy via â«´; no equal opposition, positive priority."""
        dichot = self.dichotomy(P)
        return "Satisfies (Bivalence with Positive Grounding)" if dichot == True else "Fails (No Balanced Opposition Allowed)"

    def _entails_O(self, P):
        """Test grounded entailment âŸ¼ from ğ•†."""
        nec_entail = self.grounded_entail(self.O, self.necessity(P))
        pos_entail = self.grounded_entail(self.O, self.possibility(P))
        if nec_entail == True:
            return "necessary"
        elif pos_entail == True:
            return "possible"
        else:
            return "impossible"  # Triggers privative classification

    def _detect_paradox(self, context):
        """Detect common paradox patterns based on context."""
        if "this sentence" in context.lower() or "self" in context.lower():
            return "Self-Referential (Inadmissible; Fails ğ•€â‚ Grounding)"
        elif "set" in context.lower() and "contain" in context.lower():
            return "Set-Theoretic (Pseudo-Entity Outside ğ•†)"
        return "None Detected"

# Runtime Example (for demonstration; remove or comment in production)
if __name__ == "__main__":
    analyzer = PXLAnalyzer()
    # Sample analysis: Identity law
    result = analyzer.analyze_concept("x â§Ÿ x", "Check for self-referential issues")
    print(result)
    # Sample with negation (privation)
    result_neg = analyzer.analyze_concept("âˆ¼(x â§Ÿ x)", "Negated identity")
    print(result_neg)