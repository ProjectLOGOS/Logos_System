# HEADER_TYPE: LEGACY_REWRITE_CANDIDATE
# EXECUTION: FORBIDDEN
# IMPORT: FORBIDDEN
# AUTHORITY: NONE
# DESTINATION: Logos_System_Rebuild
# ARCHIVE_AFTER_REWRITE: REQUIRED

"""
End-to-End Pipeline Integration Test

Tests the complete Phase 1â†’2 Bridge: Passive Loop â†’ IEL Generation pipeline
validating each step of the autonomous reasoning cycle.
"""

import json
import os
import subprocess
from pathlib import Path


def test_end_to_end_pipeline():
    """Test complete end-to-end pipeline execution"""
    print("ğŸ”§ Testing End-to-End Pipeline...")

    # Step 1: Verify daemon can run
    print("  âœ“ Step 1: Testing daemon execution...")
    result = subprocess.run(
        [
            "python",
            "-m",
            "logos_core.daemon.logos_daemon",
            "--once",
            "--emit-gaps",
            "--out",
            "metrics/test_status.jsonl",
        ],
        capture_output=True,
        text=True,
        cwd=os.getcwd(),
    )

    assert result.returncode == 0, f"Daemon failed: {result.stderr}"
    assert Path("metrics/test_status.jsonl").exists(), "Gap telemetry not generated"

    # Step 2: Verify gap artifacts exist
    print("  âœ“ Step 2: Checking gap detection...")
    with open("metrics/test_status.jsonl", "r") as f:
        telemetry = [json.loads(line) for line in f]

    assert len(telemetry) > 0, "No telemetry generated"
    gap_events = [
        t
        for t in telemetry
        if t.get("event_type") in ["gap_detected", "reasoning_gap_detected"]
    ]
    assert len(gap_events) > 0, "No reasoning gaps detected"

    # Step 3: Verify IEL generation
    print("  âœ“ Step 3: Testing IEL generation...")
    result = subprocess.run(
        [
            "python",
            "-m",
            "logos_core.meta_reasoning.iel_generator",
            "--from-log",
            "metrics/test_status.jsonl",
            "--out",
            "build/test_candidate.v",
        ],
        capture_output=True,
        text=True,
        cwd=os.getcwd(),
    )

    assert result.returncode == 0, f"IEL generation failed: {result.stderr}"
    assert Path("build/test_candidate.v").exists(), "IEL candidate not generated"

    # Step 4: Verify signing
    print("  âœ“ Step 4: Testing cryptographic signing...")
    result = subprocess.run(
        [
            "python",
            "-m",
            "logos_core.governance.iel_signer",
            "--sign",
            "build/test_candidate.v",
            "--key",
            "keys/iel_signing.pem",
            "--out",
            "build/test_candidate.sig",
        ],
        capture_output=True,
        text=True,
        cwd=os.getcwd(),
    )

    assert result.returncode == 0, f"IEL signing failed: {result.stderr}"
    assert Path("build/test_candidate.sig").exists(), "Signature not generated"

    # Step 5: Verify registry integration
    print("  âœ“ Step 5: Testing registry integration...")
    result = subprocess.run(
        [
            "python",
            "-m",
            "logos_core.meta_reasoning.iel_registry",
            "--add",
            "build/test_candidate.v",
            "--sig",
            "build/test_candidate.sig",
            "--registry",
            "registry/test_registry.json",
        ],
        capture_output=True,
        text=True,
        cwd=os.getcwd(),
    )

    assert result.returncode == 0, f"Registry registration failed: {result.stderr}"

    # Step 6: Verify registry listing
    print("  âœ“ Step 6: Testing registry queries...")
    result = subprocess.run(
        [
            "python",
            "-m",
            "logos_core.meta_reasoning.iel_registry",
            "--list",
            "--registry",
            "registry/test_registry.json",
        ],
        capture_output=True,
        text=True,
        cwd=os.getcwd(),
    )

    assert result.returncode == 0, f"Registry listing failed: {result.stderr}"
    assert "Registry contains" in result.stdout, "Registry listing malformed"

    # Cleanup test artifacts
    test_files = [
        "metrics/test_status.jsonl",
        "build/test_candidate.v",
        "build/test_candidate.sig",
        "registry/test_registry.json",
        "registry/test_registry.db",
    ]

    for test_file in test_files:
        if Path(test_file).exists():
            Path(test_file).unlink()

    print("ğŸ¯ End-to-End Pipeline Test: PASSED")
    return True


def test_component_interfaces():
    """Test that all components have proper CLI interfaces"""
    print("ğŸ”§ Testing Component Interfaces...")

    components = [
        "logos_core.daemon.logos_daemon",
        "logos_core.meta_reasoning.iel_generator",
        "logos_core.governance.iel_signer",
        "logos_core.meta_reasoning.iel_registry",
    ]

    for component in components:
        result = subprocess.run(
            ["python", "-m", component, "--help"],
            capture_output=True,
            text=True,
            cwd=os.getcwd(),
        )

        assert result.returncode == 0, f"Component {component} CLI broken"
        assert (
            "usage:" in result.stdout.lower() or "Usage:" in result.stdout
        ), f"Component {component} help malformed"

    print("ğŸ¯ Component Interface Test: PASSED")
    return True


def test_artifacts_validation():
    """Test that generated artifacts have proper format"""
    print("ğŸ”§ Testing Artifact Validation...")

    # Check existing artifacts
    artifacts = [
        ("metrics/agi_status.jsonl", "telemetry"),
        ("build/candidate_iel.v", "coq"),
        ("build/candidate_iel.sig", "signature"),
        ("registry/iel_registry.db", "database"),
    ]

    for artifact_path, artifact_type in artifacts:
        if Path(artifact_path).exists():
            print(f"  âœ“ Found {artifact_type}: {artifact_path}")

            if artifact_type == "signature":
                with open(artifact_path, "r") as f:
                    sig_data = json.load(f)
                assert (
                    "signature" in sig_data
                ), f"Invalid signature format in {artifact_path}"
                assert "algorithm" in sig_data, f"Missing algorithm in {artifact_path}"

            elif artifact_type == "coq":
                with open(artifact_path, "r") as f:
                    content = f.read()
                assert "Lemma" in content, f"Invalid IEL format in {artifact_path}"

    print("ğŸ¯ Artifact Validation Test: PASSED")
    return True


if __name__ == "__main__":
    try:
        test_component_interfaces()
        test_artifacts_validation()
        test_end_to_end_pipeline()
        print("\nğŸ‰ ALL TESTS PASSED - Pipeline is fully operational!")
    except AssertionError as e:
        print(f"\nâŒ TEST FAILED: {e}")
        exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ UNEXPECTED ERROR: {e}")
        exit(1)
